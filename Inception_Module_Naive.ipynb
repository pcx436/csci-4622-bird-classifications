{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import keras \n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "#for classifying the images\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "#now from main function\n",
    "from main import *\n",
    "\n",
    "data = np.load('outputFile.npz', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_data', 'image_names']\n"
     ]
    }
   ],
   "source": [
    "print(data.files)\n",
    "    \n",
    "image_data = data['image_data']\n",
    "image_names = data['image_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, x_val, y_val = split_groups(image_data, image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Alright so I will be trying the googleNet or Inception_module\n",
    "I am going off the \n",
    "https://machinelearningmastery.com/how-to-implement-major-architecture-innovations-for-convolutional-neural-networks/\n",
    "Tutorial\n",
    "\n",
    "#This model is the first one to hypertuned and hte one running is the one with the features added and just with more epochs\n",
    "#This is really annoying btw. \n",
    "#This is the very naive version\n",
    "def naive_inception_module(layer_in, f1, f2, f3):\n",
    "    # 1x1 conv\n",
    "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv2D(f2, (3,3), padding='same', activation='relu')(layer_in)\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv2D(f3, (5,5), padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis = -1)\n",
    "    flatten = Flatten()(layer_out)\n",
    "    layer_out = Dense(201, activation='softmax')(flatten)\n",
    "    \n",
    "    return layer_out\n",
    " \n",
    "# define model input\n",
    "visible = Input(shape=(102,102,3))\n",
    "# add inception module\n",
    "layer = naive_inception_module(visible, 64, 128, 32)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size= 64, epochs=15, verbose=1, validation_data = (x_val, y_val))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 102, 102, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 102, 102, 64) 256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 102, 102, 128 3584        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 102, 102, 32) 2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 102, 102, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 102, 102, 227 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2361708)      0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 201)          474703509   flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 474,709,781\n",
      "Trainable params: 474,709,781\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(7577, 102, 102, 3)\n",
      "Train on 7577 samples, validate on 1053 samples\n",
      "Epoch 1/20\n",
      "7577/7577 [==============================] - 722s 95ms/step - loss: 1850762.3421 - accuracy: 0.0062 - val_loss: 3366206.1553 - val_accuracy: 0.0047\n",
      "Epoch 2/20\n",
      "7577/7577 [==============================] - 722s 95ms/step - loss: 2175501.8038 - accuracy: 0.0100 - val_loss: 1804482.8371 - val_accuracy: 0.0104\n",
      "Epoch 3/20\n",
      "7577/7577 [==============================] - 682s 90ms/step - loss: 1553104.9908 - accuracy: 0.0154 - val_loss: 1577724.1204 - val_accuracy: 0.0104\n",
      "Epoch 4/20\n",
      "7577/7577 [==============================] - 697s 92ms/step - loss: 1481812.5663 - accuracy: 0.0245 - val_loss: 1339770.2896 - val_accuracy: 0.0133\n",
      "Epoch 5/20\n",
      "7577/7577 [==============================] - 691s 91ms/step - loss: 1222742.2860 - accuracy: 0.0313 - val_loss: 1328720.4786 - val_accuracy: 0.0133\n",
      "Epoch 6/20\n",
      "7577/7577 [==============================] - 541s 71ms/step - loss: 1212410.7312 - accuracy: 0.0337 - val_loss: 1186590.9153 - val_accuracy: 0.0085\n",
      "Epoch 7/20\n",
      "7577/7577 [==============================] - 535s 71ms/step - loss: 1019931.8999 - accuracy: 0.0441 - val_loss: 1046828.1999 - val_accuracy: 0.0123\n",
      "Epoch 8/20\n",
      "7577/7577 [==============================] - 519s 69ms/step - loss: 962774.5152 - accuracy: 0.0540 - val_loss: 1144233.5330 - val_accuracy: 0.0142\n",
      "Epoch 9/20\n",
      "7577/7577 [==============================] - 644s 85ms/step - loss: 944162.4596 - accuracy: 0.0647 - val_loss: 1014480.1479 - val_accuracy: 0.0218\n",
      "Epoch 10/20\n",
      "7577/7577 [==============================] - 662s 87ms/step - loss: 876679.3086 - accuracy: 0.0649 - val_loss: 957442.9291 - val_accuracy: 0.0199\n",
      "Epoch 11/20\n",
      "7577/7577 [==============================] - 624s 82ms/step - loss: 893803.6492 - accuracy: 0.0739 - val_loss: 954666.6263 - val_accuracy: 0.0123\n",
      "Epoch 12/20\n",
      "7577/7577 [==============================] - 500s 66ms/step - loss: 798343.2752 - accuracy: 0.0842 - val_loss: 983129.7271 - val_accuracy: 0.0123\n",
      "Epoch 13/20\n",
      "7577/7577 [==============================] - 521s 69ms/step - loss: 801938.4796 - accuracy: 0.0911 - val_loss: 898043.9386 - val_accuracy: 0.0218\n",
      "Epoch 14/20\n",
      "7577/7577 [==============================] - 521s 69ms/step - loss: 746441.5183 - accuracy: 0.1014 - val_loss: 996211.9460 - val_accuracy: 0.0152\n",
      "Epoch 15/20\n",
      "4096/7577 [===============>..............] - ETA: 3:52 - loss: 769467.5347 - accuracy: 0.1094"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Alright so I will be trying the googleNet or Inception_module\n",
    "I am going off the \n",
    "https://machinelearningmastery.com/how-to-implement-major-architecture-innovations-for-convolutional-neural-networks/\n",
    "Tutorial\n",
    "'''\n",
    "\n",
    "#This is the very naive version\n",
    "def naive_inception_module(layer_in, f1, f2, f3):\n",
    "    # 1x1 conv\n",
    "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv2D(f2, (3,3), padding='same', activation='relu')(layer_in)\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv2D(f3, (5,5), padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis = -1)\n",
    "    flatten = Flatten()(layer_out)\n",
    "    layer_out = Dense(201, activation='softmax')(flatten)\n",
    "    \n",
    "    return layer_out\n",
    " \n",
    "# define model input\n",
    "visible = Input(shape=(102,102,3))\n",
    "# add inception module\n",
    "layer = naive_inception_module(visible, 64, 128, 32)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size= 64, epochs=20, verbose=1, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting info about the data \n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(20)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def inception_module_1(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\\n    # 1x1 conv\\n    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\\n    # 3x3 conv\\n    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\\n    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\\n    # 5x5 conv\\n    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\\n    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\\n    # 3x3 max pooling\\n    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\\n    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\\n    # concatenate filters, assumes filters/channels last\\n    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\\n    return layer_out\\ndef inception_module_2(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\\n    # 1x1 conv\\n    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\\n    # 3x3 conv\\n    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\\n    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\\n    # 5x5 conv\\n    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\\n    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\\n    # 3x3 max pooling\\n    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\\n    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\\n    # concatenate filters, assumes filters/channels last\\n    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\\n    flatten = Flatten()(layer_out)\\n    layer_out = Dense(201, activation='softmax')(flatten)\\n    return layer_out\\n \\n# define model input\\nvisible = Input(shape=(102,102,3))\\n\\n# add inception module\\n# add inception block 1\\nlayer = inception_module_1(visible, 64, 96, 128, 16, 32, 32)\\n# add inception block 1\\nlayer = inception_module_2(layer, 128, 128, 192, 32, 96, 64)\\nlayer_test = layer\\n# create model\\n# create model\\nmodel = Model(inputs=visible, outputs = layer_test)\\n# summarize model\\nmodel.summary()\\n\\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\\n\\nprint(x_train.shape)\\n\\nhistory = model.fit(x_train, y_train, batch_size= 64, epochs=15, verbose=1, validation_data = (x_val, y_val))\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This section kills my kernel.... :( why\n",
    "'''def inception_module_1(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    # 1x1 conv\n",
    "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return layer_out\n",
    "def inception_module_2(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    # 1x1 conv\n",
    "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    flatten = Flatten()(layer_out)\n",
    "    layer_out = Dense(201, activation='softmax')(flatten)\n",
    "    return layer_out\n",
    " \n",
    "# define model input\n",
    "visible = Input(shape=(102,102,3))\n",
    "\n",
    "# add inception module\n",
    "# add inception block 1\n",
    "layer = inception_module_1(visible, 64, 96, 128, 16, 32, 32)\n",
    "# add inception block 1\n",
    "layer = inception_module_2(layer, 128, 128, 192, 32, 96, 64)\n",
    "layer_test = layer\n",
    "# create model\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs = layer_test)\n",
    "# summarize model\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size= 64, epochs=15, verbose=1, validation_data = (x_val, y_val))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
